{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from skimage.io import imread\n",
    "from skimage.draw import polygon\n",
    "\n",
    "# from IPython.display import display, Image, clear_output\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/src/\") # path to the root directory\n",
    "from visualization.visualize import print_image_with_point, show_sam_seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"path/to/your/folder/\"\n",
    "image_shape = (1200, 1600)  # Replace with your image shape\n",
    "\n",
    "# evaluation files\n",
    "eval_path = folder_path + \"data/cyprus_eval_frames.csv\"\n",
    "eval_path_results = folder_path + \"data/cyprus_eval_frames_results.csv\"\n",
    "cyprus_eval_frames_results_predictions = folder_path + \"data/cyprus_eval_frames_results_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mapping =  folder_path + \"/label_mapping.json\"\n",
    "with open(path_mapping, 'r') as f:\n",
    "    label_mapping = json.load(f)\n",
    "    categories = label_mapping[\"categories\"]\n",
    "    categorie_mapping = label_mapping[\"category_mapping\"]\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelme_json_to_mask_acc(json_file, image_shape):\n",
    "    \"\"\"\n",
    "    Convert all LabelMe JSON annotations to one binary mask.\n",
    "\n",
    "    :param json_file: Path to the LabelMe JSON file.\n",
    "    :param image_shape: Shape of the corresponding image (height, width).\n",
    "    :return: Binary mask as a numpy array.\n",
    "    \"\"\"\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    mask = np.zeros(image_shape[:2], dtype=np.uint8)  # Assuming image_shape is (height, width, channels)\n",
    "    \n",
    "    # Iterate through all polygons (assuming 'polygon' type annotations)\n",
    "    for shape in data['shapes']:\n",
    "        if shape['shape_type'] == 'polygon':\n",
    "            polygon_points = np.array(shape['points'])\n",
    "            rr, cc = polygon(polygon_points[:, 1], polygon_points[:, 0], image_shape)\n",
    "            mask[rr, cc] = 1\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def labelme_json_to_mask(json_file, image_shape):\n",
    "    \"\"\"\n",
    "    Convert LabelMe JSON annotations to a list of binary mask.\n",
    "\n",
    "    :param json_file: Path to the LabelMe JSON file.\n",
    "    :param image_shape: Shape of the corresponding image (height, width).\n",
    "    :return:list of Binary mask as a numpy array.\n",
    "    \"\"\"\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "      \n",
    "    masks = []\n",
    "    # Iterate through all polygons (assuming 'polygon' type annotations)\n",
    "    for shape in data['shapes']:\n",
    "        mask = np.zeros(image_shape[:2], dtype=np.uint8)  # Assuming image_shape is (height, width, channels)\n",
    "        if shape['shape_type'] == 'polygon':\n",
    "            polygon_points = np.array(shape['points'])\n",
    "            rr, cc = polygon(polygon_points[:, 1], polygon_points[:, 0], image_shape)\n",
    "            mask[rr, cc] = 1\n",
    "        np.array(mask)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "        \n",
    "def labelme_json_to_mask_and_label(json_file, image_shape):\n",
    "    \"\"\"\n",
    "    Convert LabelMe JSON annotations to a list of binary mask and labels.\n",
    "\n",
    "    :param json_file: Path to the LabelMe JSON file.\n",
    "    :param image_shape: Shape of the corresponding image (height, width).\n",
    "    :return: list of Binary mask as a numpy array.\n",
    "    :return: list of labels\n",
    "    \"\"\"\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "      \n",
    "    masks = []\n",
    "    labels = []\n",
    "    # Iterate through all polygons (assuming 'polygon' type annotations)\n",
    "    for shape in data['shapes']:\n",
    "        mask = np.zeros(image_shape[:2], dtype=np.uint8)  # Assuming image_shape is (height, width, channels)\n",
    "        if shape['shape_type'] == 'polygon':\n",
    "            polygon_points = np.array(shape['points'])\n",
    "            rr, cc = polygon(polygon_points[:, 1], polygon_points[:, 0], image_shape)\n",
    "            mask[rr, cc] = 1\n",
    "            masks.append(mask)\n",
    "            labels.append(shape['label'])\n",
    "    return masks, labels\n",
    "\n",
    "\n",
    "def calculate_metrics_sam(ground_truth_mask, predicted_mask):\n",
    "    \"\"\"\n",
    "    Calculate Precision, Recall, F1-Score, IoU, and Accuracy.\n",
    "\n",
    "    :param ground_truth_mask: Binary mask of the ground truth.\n",
    "    :param predicted_mask: Binary mask of the prediction.\n",
    "    :return: Dictionary with metrics.\n",
    "    \"\"\"\n",
    "    TP = np.sum((predicted_mask == 1) & (ground_truth_mask == 1))\n",
    "    TN = np.sum((predicted_mask == 0) & (ground_truth_mask == 0))\n",
    "    FP = np.sum((predicted_mask == 1) & (ground_truth_mask == 0))\n",
    "    FN = np.sum((predicted_mask == 0) & (ground_truth_mask == 1))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    iou = TP / (TP + FP + FN) if (TP + FP + FN) else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) else 0\n",
    "\n",
    "    return {\n",
    "        'SAM_Precision': precision,\n",
    "        'Sam_Recall': recall,\n",
    "        'Sam_F1-Score': f1_score,\n",
    "        'Sam_IoU': iou,\n",
    "        'Sam_Accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    \n",
    "def calculate_metrics_seg(seg_mask, mask, label): # TODO just give the length \n",
    "    \"\"\"\n",
    "    input:\n",
    "    - seg_mask: segmentation\n",
    "    - masks: mask to check\n",
    "    - label: correct label\n",
    "    \"\"\"\n",
    "    \n",
    "    total_px = seg_mask.shape[0] * seg_mask.shape[1]\n",
    "    gt_pos_px = 0\n",
    "    truepos_px = 0\n",
    "    \n",
    "    \n",
    "    List_cat_count = np.zeros(len(categories))\n",
    "\n",
    "    for x in range(0,seg_mask.shape[0]):\n",
    "        for y in range(0,seg_mask.shape[1]):\n",
    "            if mask[x,y] == True:\n",
    "                gt_pos_px += 1\n",
    "                id = seg_mask[int(x), int(y)]\n",
    "                List_cat_count[id] += 1\n",
    "                seg_label= categorie_mapping[categories[str(int(id))]]\n",
    "                if seg_label == label:\n",
    "                    truepos_px += 1\n",
    "                    \n",
    "    recall = truepos_px/gt_pos_px\n",
    "                    \n",
    "    return {\n",
    "        'Seg_Total_px': total_px,\n",
    "        'GT_Mask_size[px]': gt_pos_px,\n",
    "        'True_prediction_in_mask': truepos_px,\n",
    "        'Seg_recall': recall\n",
    "    }, List_cat_count\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the names and print the categories\n",
    "label_colors = {\n",
    "        0: [255, 128, 0],    # Black for road\n",
    "        1: [255, 0, 0],  # Red for label 1\n",
    "        2: [0, 255, 0],  # Green for label 2\n",
    "        3: [0, 0, 255],  # Blue for label 3\n",
    "        4: [255, 255, 0],  # Yellow for label 4\n",
    "        5: [255, 0, 255],  # Magenta for label 5\n",
    "        6: [0, 255, 255],  # Cyan for label 6\n",
    "        7: [128, 0, 0],    # Maroon for label 7\n",
    "        8: [0, 128, 0],    # Green for label 8\n",
    "        9: [0, 0, 128],    # Navy for label 9\n",
    "        10: [128, 128, 0],  # Olive for label 10\n",
    "        11: [128, 0, 128],  # Purple for label 11\n",
    "        12: [0, 128, 128],  # Teal for label 12\n",
    "        13: [192, 192, 192],  # Silver for label 13\n",
    "        14: [128, 128, 128],  # Gray for label 14\n",
    "        15: [0,0,0],  # Orange for label 15\n",
    "        16: [0, 255, 128],  # Lime for label 16\n",
    "        17: [128, 0, 255],  # Fuchsia for label 17\n",
    "        18: [128, 255, 0],  # Lime for label 19\n",
    "        # You can add more colors for additional labels as needed\n",
    "    }\n",
    "\n",
    "def get_seg_img(img,seg):\n",
    "    \"\"\"\n",
    "    This function shows the image with the segmentation\n",
    "    same ase show_img\n",
    "    \n",
    "    Parameters:\n",
    "    - img: image\n",
    "    - seg: segmentation\n",
    "    \n",
    "    Returns:\n",
    "    - img: image with segmentation\n",
    "    - color_seg: just segmentation \n",
    "    \"\"\"\n",
    "    # @TODO Rename to get_seg_img\n",
    "\n",
    "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\\\n",
    "    for label, color in label_colors.items():\n",
    "        color_seg[seg == label] = color\n",
    "    # Convert to BGR\n",
    "    #color_seg = color_seg[..., ::-1] # kehrt die Reihenfolge der Farbkan√§le um.\n",
    "\n",
    "    # Show image + mask\n",
    "    img = np.array(img) * 0.5 + color_seg * 0.5\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    return img, color_seg\n",
    "\n",
    "def load_logits( seg_path):\n",
    "    # Load logits from the specified path\n",
    "    logits = torch.load(seg_path)   \n",
    "\n",
    "    # Check if the shape matches the expected shape\n",
    "    if logits.shape == torch.Size([1, 19, 128, 128]):\n",
    "        logits = logits.float()  # Convert to 'float' data type\n",
    "        logits = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Upsample the logits to match the image shape\n",
    "        upsampled_logits = logits #nn.functional.interpolate(logits, size=img_shape, mode='bilinear', align_corners=False)\n",
    "        # Get both the maximum probabilities and their corresponding labels\n",
    "        max_probs, labels = torch.max(upsampled_logits, dim=1)\n",
    "        label = labels[0]  # Extract the most probable label matrix\n",
    "        prob = max_probs[0]  # Extract the probability matrix corresponding to the most probable labels\n",
    "    \n",
    "        return logits,label, prob  # Return both the label matrix and the probability matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Metrices for Semantic Segmentation and Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(eval_path_results)\n",
    "data = df\n",
    "\n",
    "total_acc = []\n",
    "total_iou = []\n",
    "total_f1 = []\n",
    "total_recall = []\n",
    "total_precision = []\n",
    "recall_dict = []\n",
    "precision_dict = []\n",
    "seg_results = []\n",
    "sam_results = []\n",
    "results = []\n",
    "\n",
    "# for all data in the evaluation set set\n",
    "for i in range(0, len(data)):\n",
    "    try:\n",
    "        # load data\n",
    "        x = data[\"x\"].iloc[i]\n",
    "        y = data[\"y\"].iloc[i]\n",
    "        session = data[\"session\"].iloc[i]\n",
    "        response = data[\"response\"].iloc[i]\n",
    "        frame_nr = data[\"frame_nr\"].iloc[i]\n",
    "        str_frame_nr = f\"{frame_nr:05d}\"\n",
    "\n",
    "        # get image path\n",
    "        path = folder_path + \"/data/evalset/\"\n",
    "        handLabel_path = path + \"handlabels/\" + session + \"_\" + str_frame_nr + \".json\"\n",
    "        sam_mask_path = path + \"sams/\" + session + \"_\" + str_frame_nr + \".npy\"\n",
    "        seg_path = path + \"segs/\" + session + \"_\" + str_frame_nr + \".pt\"\n",
    "        image_path = path + \"images/\" + session + \"_\" + str_frame_nr + \".jpg\"\n",
    "\n",
    "        # load image\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # load sam mask\n",
    "        sam_mask = np.load(sam_mask_path)[0]\n",
    "        labelme_mask, labels = labelme_json_to_mask_and_label(\n",
    "            handLabel_path, image_shape\n",
    "        )\n",
    "\n",
    "        # load segmask\n",
    "        seg_mask = load_logits(seg_path)[0]\n",
    "        seg_mask = nn.functional.interpolate(\n",
    "            seg_mask.float(), size=(1200, 1600), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        seg_mask = torch.argmax(seg_mask, dim=1).squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "        # calculate metrics for each grount truth mask \n",
    "        #print(len(labelme_mask))\n",
    "        for i, (mask, label) in enumerate(zip(labelme_mask, labels)):\n",
    "            \n",
    "            print(i)\n",
    "            \n",
    "            # calculate metrics sam\n",
    "            metrics_sam = calculate_metrics_sam(mask, sam_mask)\n",
    "            metrics_sam[\"session\"] = session\n",
    "            metrics_sam[\"frame_nr\"] = frame_nr\n",
    "            metrics_sam[\"mask_nr\"] = i + 1\n",
    "            sam_results.append(metrics_sam)\n",
    "\n",
    "            # if the mask is labeld, calculte the metrics for the segmentation as well\n",
    "            if label in set(categorie_mapping.values()):\n",
    "                \n",
    "                # calculate metrics seg\n",
    "                metrics_seg, list_cat_count = calculate_metrics_seg(seg_mask, mask, label)\n",
    "\n",
    "                # add the frame name to the dictionary\n",
    "                metrics_seg[\"session\"] = session\n",
    "                metrics_seg[\"frame_nr\"] = frame_nr\n",
    "                metrics_seg[\"label\"] = label\n",
    "                metrics_seg[\"mask_nr\"] = i + 1\n",
    "                seg_results.append(metrics_seg)\n",
    "\n",
    "            \n",
    "            #### Start of the sample print -------------------------------------------------------\n",
    "            PrintData = False\n",
    "            if PrintData:#label == \"ambiguous\":  # metrics_seg[\"recall\"] < 0.5:\n",
    "                print(metrics_seg)\n",
    "                for i, z in zip(list_cat_count, list(categories.values())):\n",
    "                    if i > 0:\n",
    "                        print(i, z)\n",
    "                seg_s, _ = get_seg_img(image, seg_mask)\n",
    "\n",
    "                color = [255, 0, 0]\n",
    "                color_gr = np.zeros(\n",
    "                    (1200, 1600, 3), dtype=np.uint8\n",
    "                )  # height, width, 3\\\n",
    "                color_gr[mask == True] = color\n",
    "\n",
    "                img_s = seg_s.copy()\n",
    "                for x in range(0, seg_mask.shape[0]):\n",
    "                    for y in range(0, seg_mask.shape[1]):\n",
    "                        if mask[x, y] != True:\n",
    "                            original_color = img_s[\n",
    "                                x, y\n",
    "                            ]  # Assuming img[x, y] is already in the form of a numpy array or similar\n",
    "                            blend_color = [255, 255, 255]\n",
    "                            blended_color = [\n",
    "                                (int(original_color[i]) + blend_color[i]) // 2\n",
    "                                for i in range(3)\n",
    "                            ]\n",
    "                            img_s[x, y] = blended_color\n",
    "\n",
    "                img_mask = image.copy()\n",
    "                for x in range(0, seg_mask.shape[0]):\n",
    "                    for y in range(0, seg_mask.shape[1]):\n",
    "                        if mask[x, y] != True:\n",
    "                            original_color = img_mask[\n",
    "                                x, y\n",
    "                            ]  # Assuming img[x, y] is already in the form of a numpy array or similar\n",
    "                            blend_color = [255, 255, 255]\n",
    "                            blended_color = [\n",
    "                                (int(original_color[i]) + 5 * blend_color[i]) // 6\n",
    "                                for i in range(3)\n",
    "                            ]\n",
    "                            img_mask[x, y] = blended_color\n",
    "\n",
    "                # plot image\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "                axs[0].imshow(image)\n",
    "                axs[0].set_title(\"Original Image\")\n",
    "                axs[1].imshow(img_s)\n",
    "                axs[1].set_title(\"Segmentation\")\n",
    "                # axs[2].imshow(mask, cmap='gray')\n",
    "                # axs[2].set_title(\"Groundtruth Mask\")\n",
    "                for ax in axs:\n",
    "                    ax.axis(\"off\")\n",
    "                plt.show()\n",
    "\n",
    "                # plot one image with the segmentation\n",
    "                plt.imshow(img_s)\n",
    "                # axis of\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "                # combine both masks\n",
    "                color = [0, 255, 255]\n",
    "                color_sam = np.zeros((1200, 1600, 3), dtype=np.uint8) # height, width, 3\\\n",
    "                color_sam[sam_mask == True] = color\n",
    "\n",
    "                color = [255, 0, 0]\n",
    "                color_gr = np.zeros((1200, 1600, 3), dtype=np.uint8) # height, width, 3\\\n",
    "                color_gr[mask == True] = color\n",
    "\n",
    "                #img = color_sam * 0.5 + color_gr * 0.5\n",
    "                img = seg_mask * 0.0 - mask * 0.8\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "                # plot the mask onto the segmentation\n",
    "\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "                axs[0].imshow(image)\n",
    "                axs[0].set_title(\"Original Image\")\n",
    "                axs[1].imshow(mask, cmap='gray')\n",
    "                axs[1].set_title(\"Groundtruth Mask\")\n",
    "                axs[2].imshow(img)\n",
    "                axs[2].set_title(\"Sam Mask\")\n",
    "               # axs[3].imshow(seg_mask)\n",
    "                for ax in axs:\n",
    "                    ax.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "                     # combine both masks\n",
    "                color = [0, 255, 255]\n",
    "                color_sam = np.zeros((1200, 1600, 3), dtype=np.uint8) # height, width, 3\\\n",
    "                color_sam[sam_mask == True] = color\n",
    "\n",
    "                color = [255, 0, 0]\n",
    "                color_gr = np.zeros((1200, 1600, 3), dtype=np.uint8) # height, width, 3\\\n",
    "                color_gr[mask == True] = color\n",
    "\n",
    "                #img = color_sam * 0.5 + color_gr * 0.5\n",
    "                img = seg_mask * 0.0 - sam_mask * 0.8\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "                # plot the mask onto the segmentation\n",
    "\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "                axs[0].imshow(image)\n",
    "                axs[0].set_title(\"Original Image\")\n",
    "                axs[1].imshow(mask, cmap='gray')\n",
    "                axs[1].set_title(\"Groundtruth Mask\")\n",
    "                axs[2].imshow(img)\n",
    "                axs[2].set_title(\"Sam Mask\")\n",
    "               # axs[3].imshow(seg_mask)\n",
    "                for ax in axs:\n",
    "                    ax.axis('off')\n",
    "                plt.show()\n",
    "            #### End of the sample print -------------------------------------------------------\n",
    "\n",
    "            # for each image just take one value\n",
    "            # print(\"Max: Precision\", max(result['Precision'] for result in all_metrics))\n",
    "            # print(\"Recall\", max(result['Recall'] for result in all_metrics))\n",
    "            # print(\"F1-Score\", max(result['F1-Score'] for result in all_metrics))\n",
    "            # print(\"IoU\", max(result['IoU'] for result in all_metrics))\n",
    "            # print(\"Accuracy\", max(result['Accuracy'] for result in all_metrics))\n",
    "            # total_acc.append(max(result['Accuracy'] for result in all_metrics))\n",
    "            # total_iou.append(max(result['IoU'] for result in all_metrics))\n",
    "            # total_f1.append(max(result['F1-Score'] for result in all_metrics))\n",
    "            # total_recall.append(max(result['Recall'] for result in all_metrics))\n",
    "            # total_precision.append(max(result['Precision'] for result in all_metrics))\n",
    "            # take the dictionary where the precision is the highes\n",
    "\n",
    "            # metrics_sam\n",
    "            # max_precision_dict = max(\n",
    "            #     sam_results, key=lambda x: x[\"Precision\"]\n",
    "            # )\n",
    "            # max_recall_dict = max(sam_results, key=lambda x: x[\"Recall\"])\n",
    "            # recall_dict.append(max_recall_dict)\n",
    "            # precision_dict.append(max_precision_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results in a file\n",
    "df_sam = pd.DataFrame(sam_results)\n",
    "df_seg = pd.DataFrame(seg_results)\n",
    "\n",
    "# merge such that no information is deltetd\n",
    "df = pd.merge(df_sam, df_seg, on=[\"session\", \"frame_nr\", \"mask_nr\"], how=\"outer\")\n",
    "df = df[['session', 'frame_nr','GT_Mask_size[px]', 'mask_nr','SAM_Precision', 'Sam_Recall', 'Sam_F1-Score', 'Sam_IoU',\n",
    "    'Sam_Accuracy',  'Seg_Total_px',\n",
    "    'True_prediction_in_mask', 'Seg_recall', 'label']]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(folder_path + '/data/eval_results_seg_sam.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba-cv-sam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
