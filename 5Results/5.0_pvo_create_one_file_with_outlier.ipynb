{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a file containing all data from all sessions \n",
    "- df : create one file for all gaze data points\n",
    "- df_fix : create one file with a row per fixation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/src/\")\n",
    "from visualization.visualize import (\n",
    "    print_image_with_point,\n",
    "    show_complete_fixation_with_all_frames_all_gaze,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"path/to/data/\"\n",
    "fixation_and_labels_total = folder_path + \"data/fixation_and_labels_total.csv\"\n",
    "fixation_label_total =  folder_path + \"data/fix_only_label_total.csv\"\n",
    "\n",
    "session_names = [\"Expl_1_ET_1_2023-09-05_11-56-16_ET\",\"Expl_1_ET_2_2023-09-05_12-34-24_ET\",\"Expl_1_ET_3_2023-09-05_13-10-01_ET\",\"Expl_2_ET_1_2023-09-06_10-36-37_ET\",\"Expl_2_ET_2_2023-09-06_11-08-36_ET\",\"Expl_2_ET_3_2023-09-06_11-39-21_ET\",\"Expl_3_ET_1_2023-09-06_13-24-43_ET\",\"Expl_3_ET_2_2023-09-06_13-57-57_ET\",\"Expl_3_ET_3_2023-09-06_14-28-39_ET\",\"Expl_4_ET_1_2023-09-06_18-31-33_ET\",\"Expl_4_ET_2_2023-09-06_18-57-24_ET\",\"Expl_5_ET_1_2023-09-07_18-17-19_ET\",\"Expl_5_ET_2_2023-09-07_18-48-26_ET\"]\n",
    "fixation_and_labels = [folder_path + session+ \"/fixation_and_labels_leveled.csv\" for session in session_names]\n",
    "fix_path = [folder_path + session+ \"/fixations.csv\" for session in session_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe does not exist, creating it..\n",
      "Correct session:  0  start:  13676  end:  32919  should be:  13670 32920\n",
      "Correct session:  1  start:  9880  end:  28804  should be:  9880 28805\n",
      "Correct session:  2  start:  8060  end:  29530  should be:  8060 29530\n",
      "Correct session:  3  start:  11605  end:  30679  should be:  11600 30680\n",
      "Correct session:  4  start:  8624  end:  27959  should be:  8620 27960\n",
      "Correct session:  5  start:  12164  end:  31449  should be:  12160 31450\n",
      "Correct session:  6  start:  8890  end:  28169  should be:  8890 28170\n",
      "Correct session:  7  start:  8710  end:  27719  should be:  8710 27720\n",
      "Correct session:  8  start:  7647  end:  26949  should be:  7640 26950\n",
      "Correct session:  9  start:  8600  end:  27819  should be:  8600 27820\n",
      "Correct session:  10  start:  7145  end:  26329  should be:  7145 26330\n",
      "Correct session:  11  start:  10180  end:  29249  should be:  10180 29250\n",
      "Correct session:  12  start:  8105  end:  27699  should be:  8105 27700\n"
     ]
    }
   ],
   "source": [
    "# create one huge dataframe combining from all sessions\n",
    "start_path = folder_path + \"Cyprus_start_end_frames.csv\"\n",
    "start_end_df = pd.read_csv(start_path)\n",
    "\n",
    "if False: # set to false to not accidentally overwrite the old file\n",
    "    print(\"Dataframe does not exist, creating it..\")\n",
    "    dfs =  []\n",
    "    \n",
    "    # Loop through file paths, loading each\n",
    "    for i, file_path in enumerate(fixation_and_labels):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # check if start end endframes are correct\n",
    "        if abs(df.iloc[0][\"frame_nr\"] -  start_end_df.iloc[i][\"start\"]) > 10 or abs(df.iloc[-1][\"frame_nr\"]- start_end_df.iloc[i][\"end\"]) > 10:\n",
    "            print(\"Error in session: \", i, \" start: \", df.iloc[0][\"frame_nr\"], \" end: \", df.iloc[-1][\"frame_nr\"], \" should be: \", start_end_df.iloc[i][\"start\"], start_end_df.iloc[i][\"end\"])\n",
    "        else :\n",
    "            print(\"Correct session: \", i, \" start: \", df.iloc[0][\"frame_nr\"], \" end: \", df.iloc[-1][\"frame_nr\"], \" should be: \", start_end_df.iloc[i][\"start\"], start_end_df.iloc[i][\"end\"])\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # add a column with the toal duration of the session\n",
    "    for session, group in df.groupby(\"session\"):\n",
    "        # caclulate the difference between the max and the min\n",
    "        duration = group[\"timestamp_[ns]\"].max() - group[\"timestamp_[ns]\"].min()\n",
    "        df.loc[df['session'] == session, 'session_duration']  = duration\n",
    "    \n",
    "    # rename columns\n",
    "    df[\"fixation_sum_label\"] = df[\"fix_annotation_max_sum\"]\n",
    "    df[\"fixation_pXc_label\"] = df[\"fix_annotation_max_pXc\"]\n",
    "    df[\"fixation_x\"] = df[\"fixation_x_[px]\"]\n",
    "    df[\"fixation_y\"] = df[\"fixation_y_[px]\"]\n",
    "    df[\"start_timestamp_ns\"] = df[\"start_timestamp_[ns]\"]\n",
    "    df[\"end_timestamp_ns\"] = df[\"end_timestamp_[ns]\"]\n",
    "    df[\"duration_ms\"] = df[\"duration_[ms]\"]\n",
    "    \n",
    "    # only keep relevant columns and rearrange them\n",
    "    df = df[['section_id', 'recording_id', 'timestamp_[ns]', 'frame_nr', 'session',\n",
    "       'x', 'y', \n",
    "       'start_timestamp_ns', 'end_timestamp_ns', 'duration_ms',\n",
    "       'fixation_x', 'fixation_y', 'azimuth_[deg]',\n",
    "       'fixation_id',\n",
    "      'fixation_sum_label',\n",
    "       'level_sum_annotation', 'fixation_pXc_label',\n",
    "       'level_pXc_annotation', 'session_duration']]\n",
    "    \n",
    "    \n",
    "    # save the complete dataframe\n",
    "    df.to_csv(fixation_and_labels_total , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create df_fix\n",
    "This dataframe only contains one row per fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24365"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if levelsum is LEVEL_4 replace fix_annotation_max_sum with ambiguous\n",
    "df.loc[df['level_sum_annotation'] == 4, 'fixation_sum_label'] = \"ambiguous\"\n",
    "df.loc[df['level_pXc_annotation'] == 4, 'fixation_pXc_label'] = \"ambiguous\"\n",
    "\n",
    "# just take relevant columns\n",
    "df_fix = df[[ 'session', 'session_duration','fixation_id',\n",
    "       'start_timestamp_ns', 'end_timestamp_ns', 'duration_ms',\n",
    "       'fixation_x', 'fixation_y', \n",
    "       'fixation_sum_label','fixation_pXc_label','level_sum_annotation', 'level_pXc_annotation']].copy()\n",
    "\n",
    "# frop duplicates such that per fixation only one row remains\n",
    "df_fix.drop_duplicates(inplace=True)\n",
    "len(df_fix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>fixation_id</th>\n",
       "      <th>start_timestamp_ns</th>\n",
       "      <th>end_timestamp_ns</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>fixation_x</th>\n",
       "      <th>fixation_y</th>\n",
       "      <th>fixation_sum_label</th>\n",
       "      <th>fixation_pXc_label</th>\n",
       "      <th>level_sum_annotation</th>\n",
       "      <th>level_pXc_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [session, session_duration, fixation_id, start_timestamp_ns, end_timestamp_ns, duration_ms, fixation_x, fixation_y, fixation_sum_label, fixation_pXc_label, level_sum_annotation, level_pXc_annotation]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows where fixation_sum_label is more than one word -> sanity check\n",
    "df_fix.loc[df_fix['fixation_sum_label'].str.contains(\"{\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate outliers\n",
    "def mad_outlier(data, threshold=3.5):\n",
    "    \"\"\" Median Absolute deviation based outlier detection.\n",
    "    Returns a booelan mask (True if z > threshold, else False).\"\"\"\n",
    "    median = np.median(data)\n",
    "    mad = np.median(np.abs(data - median))\n",
    "    modified_z_score = 0.6745 * (data - median) / mad\n",
    "    return modified_z_score > threshold\n",
    "\n",
    "# add a column which indicates if the fixation is an outlier\n",
    "df_fix.loc[:, 'is_outlier'] = mad_outlier(df_fix.duration_ms)\n",
    "\n",
    "# save the complete dataframe\n",
    "df_fix.to_csv(fixation_label_total, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba-cv-sam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
