{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the the Dataframs\n",
    "In this notebook merges the different data files for each session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "This script contains helper functions for loading and matching data.\n",
    "It matches the csv with the labels (results from SAM_SEGformer) to the fixation data(Pupil Labs Algorithm).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def match_worldtime_label(dfw, dfl):\n",
    "    \"\"\"\n",
    "    Match rows from df1 to corresponding rows in df2 based on the 'frame' column.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame with a 'frame' column.\n",
    "    df2 (pd.DataFrame): Second DataFrame to match with df1.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing matched rows from df1 and df2.\n",
    "    \"\"\"\n",
    "    m1 = dfw.merge(dfl, on=\"frame_nr\", how=\"inner\")\n",
    "    m2 = dfl.merge(dfw, on=\"frame_nr\", how=\"inner\")\n",
    "    return m1, m2\n",
    "\n",
    "\n",
    "def match_fixation(df, dff):\n",
    "    \"\"\"\n",
    "    Match rows from df with rows in dff based on start and end times.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to match with dff.\n",
    "    dff (pd.DataFrame): Third DataFrame with start and end times.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing matched rows from df and dff.\n",
    "    \"\"\"\n",
    "    result_rows = []\n",
    "    non_fixation_row = []\n",
    "\n",
    "    dff[\"section id fixation\"] = dff[\"section id\"]\n",
    "    dff[\"recording id fixation\"] = dff[\"recording id\"]\n",
    "    dff = dff.drop(columns=[\"section id\", \"recording id\"])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        time = row[\n",
    "            \"timestamp [ns]\"\n",
    "        ]  # Assuming 'time' column in df corresponds to start time.\n",
    "\n",
    "        matching_rows = dff[\n",
    "            (dff[\"start timestamp [ns]\"] <= time) & (dff[\"end timestamp [ns]\"] >= time)\n",
    "        ]\n",
    "\n",
    "        if not matching_rows.empty:\n",
    "            matching_row = matching_rows.iloc[0]\n",
    "            combined_row = pd.concat([row, matching_row])\n",
    "            result_rows.append(combined_row)\n",
    "            if matching_rows.shape[0] > 1:\n",
    "                print(f\"Warning: Multiple matching rows found for time {time}.\")\n",
    "        else:\n",
    "            non_fixation_row.append(row)\n",
    "\n",
    "    if result_rows:\n",
    "        result_df = pd.concat(result_rows, axis=1).T\n",
    "    else:\n",
    "        result_df = pd.DataFrame(columns=df.columns.tolist() + dff.columns.tolist())\n",
    "\n",
    "    return result_df, non_fixation_row\n",
    "\n",
    "\n",
    "def combine_sort_csv_files(folder_path, output_file=None):\n",
    "    # List to hold data from all CSV files\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read the CSV file and append to list\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames in the list\n",
    "    label_df = pd.concat(dfs, ignore_index=True)\n",
    "    # Sort by 'frame_nr' column\n",
    "    sorted_df = label_df.sort_values(by=\"frame_nr\", ignore_index=True)\n",
    "    # Reset index\n",
    "    sorted_df.reset_index(drop=True, inplace=True).drop_duplicates()\n",
    "    try:\n",
    "        sorted_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Write the sorted DataFrame to a new CSV file\n",
    "    if output_file != None:\n",
    "        sorted_df.to_csv(output_file, index=False)\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "def load_merge_csv(session_name, folder_path):\n",
    "    \"\"\"\n",
    "    Load the three CSV files and merge them together.\n",
    "\n",
    "    Parameters:\n",
    "    session_name (str): Name of the session.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing the merged data.\n",
    "    \"\"\"\n",
    "    fix_path = folder_path + session_name + \"/fixations.csv\"\n",
    "    world_path = folder_path + session_name + \"/world_timestamps.csv\"\n",
    "    labels_certain_path = folder_path + session_name + \"/all_labels_newseg.csv\"\n",
    "\n",
    "    fixations_df = pd.read_csv(fix_path)\n",
    "    world_timestamps_df = pd.read_csv(world_path)\n",
    "    label_df = pd.read_csv(labels_certain_path)\n",
    "    world_timestamps_df[\"frame_nr\"] = world_timestamps_df.index\n",
    "\n",
    "    # megere the frames\n",
    "    matched_df_A, b = match_worldtime_label(world_timestamps_df, label_df)\n",
    "    final_matched_df, non_fix_row = match_fixation(matched_df_A, fixations_df)\n",
    "\n",
    "    return final_matched_df, non_fix_row, world_timestamps_df, fixations_df, label_df\n",
    "\n",
    "\n",
    "def cut_df_to_session(df, start_frame, end_frame):\n",
    "    \"\"\"\n",
    "    Cut the dataframe to the session start and end frame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to cut.\n",
    "    start_frame (int): Start frame of the session.\n",
    "    end_frame (int): End frame of the session.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing only the frames from start to end.\n",
    "\n",
    "    \"\"\"\n",
    "    df2 = df[(df[\"frame_nr\"] >= start_frame) & (df[\"frame_nr\"] <= end_frame)]\n",
    "    return df2\n",
    "\n",
    "\n",
    "def check_matching(\n",
    "    label_df,\n",
    "    final_matched_df,\n",
    "    final_matched_insession_df,\n",
    "    non_fix_row,\n",
    "    fixations_df,\n",
    "    start_frame,\n",
    "    end_frame,\n",
    "):\n",
    "    \"\"\"\n",
    "    Check if the matching was done correctly.\n",
    "    \"\"\"\n",
    "    if len(label_df) > len(final_matched_df) + len(non_fix_row):\n",
    "        print(\"     Error: Some rows were lost during matching.\")\n",
    "    if len(label_df) + len(non_fix_row) < len(final_matched_df):\n",
    "        print(\"     Error: Some rows were duplicated during matching.\")\n",
    "    if (\n",
    "        final_matched_insession_df.iloc[0][\"section id\"]\n",
    "        != final_matched_insession_df.iloc[0][\"section id fixation\"]\n",
    "    ):\n",
    "        print(\"     Error: The section ids do not match.\")\n",
    "    if final_matched_insession_df[\"fixation id\"].nunique() < (\n",
    "        ((end_frame - start_frame) / 30) * 3\n",
    "    ):\n",
    "        fixations_df = fixations_df[\n",
    "            (\n",
    "                fixations_df[\"end timestamp [ns]\"]\n",
    "                >= final_matched_insession_df[\"timestamp [ns]\"][0]\n",
    "            )\n",
    "            & (\n",
    "                fixations_df[\"start timestamp [ns]\"]\n",
    "                <= final_matched_insession_df[\"timestamp [ns]\"].iloc[-1]\n",
    "            )\n",
    "        ]\n",
    "        fix_in_session = fixations_df[\"fixation id\"].nunique()\n",
    "        print(f\"    There are {fix_in_session} fixation events\")\n",
    "        print(\n",
    "            f\"    With {(end_frame - start_frame)} frames, 30 fps and three fixations/sec on average, there should be at least {(end_frame-start_frame)/30 *3} fixations.\"\n",
    "        )\n",
    "    if (\n",
    "        abs(final_matched_insession_df.iloc[0][\"frame_nr\"] - start_frame) > 10\n",
    "        or abs(final_matched_insession_df.iloc[-1][\"frame_nr\"] - end_frame) > 10\n",
    "    ):\n",
    "        print(\n",
    "            \"     start: \",\n",
    "            final_matched_insession_df.iloc[0][\"frame_nr\"],\n",
    "            \" end: \",\n",
    "            final_matched_insession_df.iloc[-1][\"frame_nr\"],\n",
    "            \" should be: \",\n",
    "            start_frame,\n",
    "            end_frame,\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"    Finished checking matching(checked for duplicated or lost rows, wrong section ids, fixation ammount, start/endframe).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  for all sessions create the fixation_and_labels files (all gaza datapoints with their labels and fixations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all sessions\n",
    "start_end_path = (\n",
    "    \"/start_end_frames.csv\"  # add the path to the file with the start and end frames\n",
    ")\n",
    "folder_path = \"/data/\"  # path to the folder with the data\n",
    "start_end = pd.read_csv(start_end_path)\n",
    "for i, (index, row) in enumerate(start_end.iterrows()):\n",
    "    if True:\n",
    "        session_name = row[\"session\"]\n",
    "        start_frame = row[\"start\"]\n",
    "        end_frame = row[\"end\"]\n",
    "\n",
    "        fixation_and_labels = (\n",
    "            folder_path + session_name + \"/fixation_and_labels.csv\"\n",
    "        )  # might need to be changed according to the folder structure\n",
    "\n",
    "        print(f\"Processing session {session_name}...\")\n",
    "\n",
    "        final_matched_df, non_fix_row, world_timestamps_df, fixations_df, label_df = (\n",
    "            load_merge_csv(session_name=session_name, folder_path=folder_path)\n",
    "        )\n",
    "        final_matched_insession_df = cut_df_to_session(\n",
    "            final_matched_df, start_frame, end_frame\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # Check if everything is correct\n",
    "        # print the ammount of rows which are not in the experiment session\n",
    "        print(\n",
    "            f\"    Deleted {len(final_matched_insession_df) - len(final_matched_insession_df)} rows which are not in experiment session.\"\n",
    "        )\n",
    "        check_matching(\n",
    "            label_df,\n",
    "            final_matched_df,\n",
    "            final_matched_insession_df,\n",
    "            non_fix_row,\n",
    "            fixations_df,\n",
    "            start_frame,\n",
    "            end_frame,\n",
    "        )\n",
    "\n",
    "        # final correcion of df\n",
    "        try:\n",
    "            final_matched_insession_df.drop(\n",
    "                columns=[\"section id fixation\", \"recording id fixation\"], inplace=True\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            final_matched_insession_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # store the final df\n",
    "        final_matched_insession_df.to_csv(fixation_and_labels)\n",
    "        print(len(final_matched_insession_df), len(label_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba-cv-sam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
